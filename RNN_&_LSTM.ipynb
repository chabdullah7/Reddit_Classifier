{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LRa9LabZ0M4S",
        "qSg40ZyP0sNn",
        "edFbgSgY0xgj",
        "C_BhbUIF0_Tk",
        "VJxa06XR2Iln",
        "SheyGPow47WH",
        "TB18r4SO5vWj",
        "533gohom6ZgV",
        "34E-jQ7T9Nip",
        "ws7exqZ5-Eqf",
        "VU2754aS-bbk",
        "hlnz7nBoAk4i",
        "MUne0bMTGnTZ",
        "EviejHdeGrLo",
        "ho0zF3_O8upm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset"
      ],
      "metadata": {
        "id": "LRa9LabZ0M4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/reddit_posts_and_comments.csv')\n",
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IzjCbf3bzIUS",
        "outputId": "f8dd4009-448c-43b8-9498-a257f6cd811e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              post_title  \\\n",
              "0             [D] - NeurIPS'2025 Reviews   \n",
              "1             [D] - NeurIPS'2025 Reviews   \n",
              "2             [D] - NeurIPS'2025 Reviews   \n",
              "3             [D] - NeurIPS'2025 Reviews   \n",
              "4             [D] - NeurIPS'2025 Reviews   \n",
              "5              [D] Self-Promotion Thread   \n",
              "6              [D] Self-Promotion Thread   \n",
              "7              [D] Self-Promotion Thread   \n",
              "8              [D] Self-Promotion Thread   \n",
              "9              [D] Self-Promotion Thread   \n",
              "10  [D] Tried of the same review pattern   \n",
              "11  [D] Tried of the same review pattern   \n",
              "12  [D] Tried of the same review pattern   \n",
              "13  [D] Tried of the same review pattern   \n",
              "14  [D] Tried of the same review pattern   \n",
              "15          [D] - NeurIPS'2025 D&B Track   \n",
              "16          [D] - NeurIPS'2025 D&B Track   \n",
              "17          [D] - NeurIPS'2025 D&B Track   \n",
              "18          [D] - NeurIPS'2025 D&B Track   \n",
              "19          [D] - NeurIPS'2025 D&B Track   \n",
              "\n",
              "                                            post_text        subreddit  \\\n",
              "0   Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning   \n",
              "1   Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning   \n",
              "2   Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning   \n",
              "3   Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning   \n",
              "4   Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning   \n",
              "5   Please post your personal projects, startups, ...  MachineLearning   \n",
              "6   Please post your personal projects, startups, ...  MachineLearning   \n",
              "7   Please post your personal projects, startups, ...  MachineLearning   \n",
              "8   Please post your personal projects, startups, ...  MachineLearning   \n",
              "9   Please post your personal projects, startups, ...  MachineLearning   \n",
              "10  Lately, I’ve been really disappointed with the...  MachineLearning   \n",
              "11  Lately, I’ve been really disappointed with the...  MachineLearning   \n",
              "12  Lately, I’ve been really disappointed with the...  MachineLearning   \n",
              "13  Lately, I’ve been really disappointed with the...  MachineLearning   \n",
              "14  Lately, I’ve been really disappointed with the...  MachineLearning   \n",
              "15  # Hey everyone,\\n\\nI think it's a good idea to...  MachineLearning   \n",
              "16  # Hey everyone,\\n\\nI think it's a good idea to...  MachineLearning   \n",
              "17  # Hey everyone,\\n\\nI think it's a good idea to...  MachineLearning   \n",
              "18  # Hey everyone,\\n\\nI think it's a good idea to...  MachineLearning   \n",
              "19  # Hey everyone,\\n\\nI think it's a good idea to...  MachineLearning   \n",
              "\n",
              "             post_author                                           post_url  \\\n",
              "0   Proof-Marsupial-5367  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "1   Proof-Marsupial-5367  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "2   Proof-Marsupial-5367  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "3   Proof-Marsupial-5367  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "4   Proof-Marsupial-5367  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "5          AutoModerator  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "6          AutoModerator  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "7          AutoModerator  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "8          AutoModerator  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "9          AutoModerator  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "10             MalumaDev  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "11             MalumaDev  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "12             MalumaDev  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "13             MalumaDev  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "14             MalumaDev  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "15   Some-Landscape-4763  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "16   Some-Landscape-4763  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "17   Some-Landscape-4763  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "18   Some-Landscape-4763  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "19   Some-Landscape-4763  https://www.reddit.com/r/MachineLearning/comme...   \n",
              "\n",
              "    post_upvotes  post_downvotes  comment_upvotes  comment_downvotes  \\\n",
              "0            203               0               77                  0   \n",
              "1            203               0               36                  0   \n",
              "2            203               0               63                  0   \n",
              "3            203               0               33                  0   \n",
              "4            203               0               34                  0   \n",
              "5             13               0                2                  0   \n",
              "6             13               0                2                  0   \n",
              "7             13               0                1                  0   \n",
              "8             13               0                1                  0   \n",
              "9             13               0                1                  0   \n",
              "10            71               0               38                  0   \n",
              "11            71               0               21                  0   \n",
              "12            71               0               13                  0   \n",
              "13            71               0               11                  0   \n",
              "14            71               0               10                  0   \n",
              "15            17               0                4                  0   \n",
              "16            17               0                3                  0   \n",
              "17            17               0                3                  0   \n",
              "18            17               0                3                  0   \n",
              "19            17               0                4                  0   \n",
              "\n",
              "                                         comment_text        comment_author  \n",
              "0   Friendly reminder that reviews this year are s...    ChoiceStranger2898  \n",
              "1   I had a dream recently where my upcoming avera...               popeldo  \n",
              "2   I will treat the scores as a divine interventi...        matcha-coconut  \n",
              "3   July 24, so as long as it's July 24 somewhere ...                SmolLM  \n",
              "4   Well, if you feel heart-broken, be assured tha...       Marionberry6886  \n",
              "5   # Your Creation, Your Proof. Get It Free.\\n\\nA...       Woundedhealer4u  \n",
              "6   # [A daily Chronicle of AI Innovations in July...               enoumen  \n",
              "7   I've been working on CocoIndex - super simple ...  Whole-Assignment6240  \n",
              "8   🧵 Finance Copilot – AI for your messy P&L file...   Due-Cauliflower5383  \n",
              "9   I need to chase the latest research on arXiv. ...         Used-Sock-130  \n",
              "10  Yeah, I have noticed the same things. I am now...                 qalis  \n",
              "11  It has certainly gotten worse in recent years....               st8ic88  \n",
              "12  I think authors should be able to evaluate the...           superchamci  \n",
              "13  Taking from another field into machine learnin...    No_Efficiency_1144  \n",
              "14  I also have seen this pattern with my reviews....          Fair-Ask2270  \n",
              "15                            4-4-3-2 fingers crossed   Some-Landscape-4763  \n",
              "16  Does anyone know if we are allowed to edit the...  Psychological-Cow318  \n",
              "17  5/4/3/3 with confidence 2/4/4/4 ... hoping wit...                kaitzu  \n",
              "18  [https://papercopilot.com/statistics/neurips-s...           coderpotato  \n",
              "19  5-5-3 and 4-4-4-5.\\nI read that the Datasets t...      Antique_Most7958  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9be7b118-ed1f-4ff6-b7e9-40d97d92e653\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_title</th>\n",
              "      <th>post_text</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>post_author</th>\n",
              "      <th>post_url</th>\n",
              "      <th>post_upvotes</th>\n",
              "      <th>post_downvotes</th>\n",
              "      <th>comment_upvotes</th>\n",
              "      <th>comment_downvotes</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>comment_author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[D] - NeurIPS'2025 Reviews</td>\n",
              "      <td>Hey everyone,\\n\\nNeurIPS 2025 reviews should b...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Proof-Marsupial-5367</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>Friendly reminder that reviews this year are s...</td>\n",
              "      <td>ChoiceStranger2898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[D] - NeurIPS'2025 Reviews</td>\n",
              "      <td>Hey everyone,\\n\\nNeurIPS 2025 reviews should b...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Proof-Marsupial-5367</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>I had a dream recently where my upcoming avera...</td>\n",
              "      <td>popeldo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[D] - NeurIPS'2025 Reviews</td>\n",
              "      <td>Hey everyone,\\n\\nNeurIPS 2025 reviews should b...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Proof-Marsupial-5367</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>I will treat the scores as a divine interventi...</td>\n",
              "      <td>matcha-coconut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[D] - NeurIPS'2025 Reviews</td>\n",
              "      <td>Hey everyone,\\n\\nNeurIPS 2025 reviews should b...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Proof-Marsupial-5367</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>July 24, so as long as it's July 24 somewhere ...</td>\n",
              "      <td>SmolLM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[D] - NeurIPS'2025 Reviews</td>\n",
              "      <td>Hey everyone,\\n\\nNeurIPS 2025 reviews should b...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Proof-Marsupial-5367</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>Well, if you feel heart-broken, be assured tha...</td>\n",
              "      <td>Marionberry6886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[D] Self-Promotion Thread</td>\n",
              "      <td>Please post your personal projects, startups, ...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td># Your Creation, Your Proof. Get It Free.\\n\\nA...</td>\n",
              "      <td>Woundedhealer4u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[D] Self-Promotion Thread</td>\n",
              "      <td>Please post your personal projects, startups, ...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td># [A daily Chronicle of AI Innovations in July...</td>\n",
              "      <td>enoumen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[D] Self-Promotion Thread</td>\n",
              "      <td>Please post your personal projects, startups, ...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I've been working on CocoIndex - super simple ...</td>\n",
              "      <td>Whole-Assignment6240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[D] Self-Promotion Thread</td>\n",
              "      <td>Please post your personal projects, startups, ...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>🧵 Finance Copilot – AI for your messy P&amp;L file...</td>\n",
              "      <td>Due-Cauliflower5383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[D] Self-Promotion Thread</td>\n",
              "      <td>Please post your personal projects, startups, ...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I need to chase the latest research on arXiv. ...</td>\n",
              "      <td>Used-Sock-130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[D] Tried of the same review pattern</td>\n",
              "      <td>Lately, I’ve been really disappointed with the...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>MalumaDev</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>Yeah, I have noticed the same things. I am now...</td>\n",
              "      <td>qalis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[D] Tried of the same review pattern</td>\n",
              "      <td>Lately, I’ve been really disappointed with the...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>MalumaDev</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>It has certainly gotten worse in recent years....</td>\n",
              "      <td>st8ic88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[D] Tried of the same review pattern</td>\n",
              "      <td>Lately, I’ve been really disappointed with the...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>MalumaDev</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>I think authors should be able to evaluate the...</td>\n",
              "      <td>superchamci</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[D] Tried of the same review pattern</td>\n",
              "      <td>Lately, I’ve been really disappointed with the...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>MalumaDev</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>Taking from another field into machine learnin...</td>\n",
              "      <td>No_Efficiency_1144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[D] Tried of the same review pattern</td>\n",
              "      <td>Lately, I’ve been really disappointed with the...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>MalumaDev</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>I also have seen this pattern with my reviews....</td>\n",
              "      <td>Fair-Ask2270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[D] - NeurIPS'2025 D&amp;B Track</td>\n",
              "      <td># Hey everyone,\\n\\nI think it's a good idea to...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Some-Landscape-4763</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4-4-3-2 fingers crossed</td>\n",
              "      <td>Some-Landscape-4763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[D] - NeurIPS'2025 D&amp;B Track</td>\n",
              "      <td># Hey everyone,\\n\\nI think it's a good idea to...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Some-Landscape-4763</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Does anyone know if we are allowed to edit the...</td>\n",
              "      <td>Psychological-Cow318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[D] - NeurIPS'2025 D&amp;B Track</td>\n",
              "      <td># Hey everyone,\\n\\nI think it's a good idea to...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Some-Landscape-4763</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5/4/3/3 with confidence 2/4/4/4 ... hoping wit...</td>\n",
              "      <td>kaitzu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[D] - NeurIPS'2025 D&amp;B Track</td>\n",
              "      <td># Hey everyone,\\n\\nI think it's a good idea to...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Some-Landscape-4763</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[https://papercopilot.com/statistics/neurips-s...</td>\n",
              "      <td>coderpotato</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[D] - NeurIPS'2025 D&amp;B Track</td>\n",
              "      <td># Hey everyone,\\n\\nI think it's a good idea to...</td>\n",
              "      <td>MachineLearning</td>\n",
              "      <td>Some-Landscape-4763</td>\n",
              "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5-5-3 and 4-4-4-5.\\nI read that the Datasets t...</td>\n",
              "      <td>Antique_Most7958</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9be7b118-ed1f-4ff6-b7e9-40d97d92e653')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9be7b118-ed1f-4ff6-b7e9-40d97d92e653 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9be7b118-ed1f-4ff6-b7e9-40d97d92e653');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0433c1ed-9e85-4470-b760-3b67afb2a616\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0433c1ed-9e85-4470-b760-3b67afb2a616')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0433c1ed-9e85-4470-b760-3b67afb2a616 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5708,\n  \"fields\": [\n    {\n      \"column\": \"post_title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1393,\n        \"samples\": [\n          \"Three months ago I woke up and decided that I needed to set a good lifestyle example for my kids\",\n          \"Being scared doesn't necessarily mean you shouldn't do it [image]\",\n          \"Everytime I'm all groomed/look great, I never seem to run into any women.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1258,\n        \"samples\": [\n          \"Hi all I'm 24, i started gambling at 19 and now it's messing with my life. Not just the money, I'm losing everything and everyone. No matter how hard I try to quit I find myself back at it again please suggest me something.\",\n          \"for context, from where i live mental illness is seen as a taboo and people have generalised anybody who's mentally ill as \\\"crazy.\\\" it's basically a synonym and an insult. i know that i shouldn't beat myself up over getting diagnosed with MDD and PTSD, that's the logical rational most utilitarian choice i can make but holy fuck i hate myself for it. the culture has deeply engrained in my psyche where i sometimes believe that i am crazy. the shame of other family members, friends, other peering eyes is nigh unavoidable. it makes me regret ever going to a shrink. how do youse manage to cope with seeing depression or any ol mental illness diagnosed to your name.\",\n          \"As the title asks, I'm wondering if anyone knows if a workshop-only registration can access the poster sessions and/or the social events? Or do I need a conference registration to access those?\\n\\nIt's surprisingly hard to find this answer on ICML official sources, but maybe I just couldn't find it. This is my first ICML, so if anyone could help answer this it would be greatly appreciated. Thanks! \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subreddit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"MachineLearning\",\n          \"depression\",\n          \"povertyfinance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1281,\n        \"samples\": [\n          \"Neither-Treat-4655\",\n          \"mkpsychologylover\",\n          \"CHERWASHERE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_url\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1442,\n        \"samples\": [\n          \"https://i.redd.it/cr45wawd12cf1.jpeg\",\n          \"https://www.reddit.com/r/ADHD/comments/1m8958p/hyperfocus/\",\n          \"https://www.reddit.com/r/ADHD/comments/1m8oomk/what_if_i_get_wrongly_diagnosed/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_upvotes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 545,\n        \"min\": 0,\n        \"max\": 11833,\n        \"num_unique_values\": 297,\n        \"samples\": [\n          435,\n          67,\n          1085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_downvotes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_upvotes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 285,\n        \"min\": -40,\n        \"max\": 14349,\n        \"num_unique_values\": 361,\n        \"samples\": [\n          82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_downvotes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5292,\n        \"samples\": [\n          \"Your name gives me the impression you may be around 22. Thats a hard time in life. Nevermind if you had it rough for the first 22. I'm sorry you're in the thick of it right now. I know it seems impossible, but i want you to know, it gets better. We're here for you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3876,\n        \"samples\": [\n          \"LoudSilence16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Select Relevant Columns"
      ],
      "metadata": {
        "id": "qSg40ZyP0sNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['post_text', 'subreddit']]\n",
        "\n",
        "print(\"Shape of DataFrame:\", df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obFbeH5YzIWz",
        "outputId": "68358a00-4471-464d-cfa6-9a4f4f470a38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame: (5708, 2)\n",
            "                                           post_text        subreddit\n",
            "0  Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning\n",
            "1  Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning\n",
            "2  Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning\n",
            "3  Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning\n",
            "4  Hey everyone,\\n\\nNeurIPS 2025 reviews should b...  MachineLearning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Select Subreddit Classes"
      ],
      "metadata": {
        "id": "edFbgSgY0xgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_subreddits = ['Alzheimers', 'povertyfinance', 'GetMotivated']\n",
        "\n",
        "df = df[df['subreddit'].isin(allowed_subreddits)]\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "print(\"Shape after filtering:\", df.shape)\n",
        "print(df['subreddit'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzN5FQXFzIZb",
        "outputId": "b047df9f-0914-4ee0-b99a-e07721bfab8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after filtering: (1256, 2)\n",
            "subreddit\n",
            "povertyfinance    420\n",
            "Alzheimers        419\n",
            "GetMotivated      417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualize Class Distribution\n"
      ],
      "metadata": {
        "id": "C_BhbUIF0_Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df, x='subreddit', palette='pastel')\n",
        "\n",
        "plt.title('Post Count per Subreddit Class')\n",
        "plt.xlabel('Subreddit')\n",
        "plt.ylabel('Number of Posts')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kyaCFoHuzIb_",
        "outputId": "ca8e8dea-7be2-44d0-80a2-6ba272fe3748"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2700630344.py:8: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(data=df, x='subreddit', palette='pastel')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Preprocessing"
      ],
      "metadata": {
        "id": "0cOQyedR1pRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Cleaning, Remove Stopwords, & Tokenization"
      ],
      "metadata": {
        "id": "VJxa06XR2Iln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install clean-text nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIOpP7V4zIee",
        "outputId": "bf05015a-004e-426f-f0df-afd0a873e988"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clean-text in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from clean-text) (1.7.0)\n",
            "Requirement already satisfied: ftfy<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from clean-text) (6.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleantext import clean\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "#Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#Text Cleaning\n",
        "def preprocess_text(text):\n",
        "\n",
        "    text = clean(text,\n",
        "                 fix_unicode=True,\n",
        "                 to_ascii=True,\n",
        "                 lower=True,\n",
        "                 no_urls=True,\n",
        "                 no_emails=True,\n",
        "                 no_phone_numbers=True,\n",
        "                 no_currency_symbols=True,\n",
        "                 no_punct=True,\n",
        "                 replace_with_punct=\"\",\n",
        "                 replace_with_url=\"\",\n",
        "                 replace_with_email=\"\",\n",
        "                 replace_with_phone_number=\"\",\n",
        "                 replace_with_currency_symbol=\"\"\n",
        "                 )\n",
        "\n",
        "    #Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    #Remove stopwords\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "\n",
        "    return filtered_tokens\n",
        "\n",
        "#Apply to post_text column\n",
        "df['clean_tokens'] = df['post_text'].astype(str).apply(preprocess_text)\n",
        "\n",
        "\n",
        "print(df[['post_text', 'clean_tokens']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElJHsGAqzIg3",
        "outputId": "db9ed5d4-1fc0-4abf-ff73-40bcc70e1273"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           post_text  \\\n",
            "0  Two years ago I posted the following message o...   \n",
            "1  Two years ago I posted the following message o...   \n",
            "2  Two years ago I posted the following message o...   \n",
            "3  Two years ago I posted the following message o...   \n",
            "4  Two years ago I posted the following message o...   \n",
            "\n",
            "                                        clean_tokens  \n",
            "0  [two, years, ago, posted, following, message, ...  \n",
            "1  [two, years, ago, posted, following, message, ...  \n",
            "2  [two, years, ago, posted, following, message, ...  \n",
            "3  [two, years, ago, posted, following, message, ...  \n",
            "4  [two, years, ago, posted, following, message, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_tokens = preprocess_text(\"You are stronger than you think. Never give up — every failure is a step toward success!\")\n",
        "cleaned_tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PJzUGgjzIjU",
        "outputId": "edd8f823-2c29-4c59-e892-90e1e2da6736"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stronger',\n",
              " 'think',\n",
              " 'never',\n",
              " 'give',\n",
              " 'every',\n",
              " 'failure',\n",
              " 'step',\n",
              " 'toward',\n",
              " 'success']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Label Encoding"
      ],
      "metadata": {
        "id": "SheyGPow47WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['label'] = label_encoder.fit_transform(df['subreddit'])\n",
        "\n",
        "\n",
        "print(df[['subreddit', 'label']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7S2Fi7NzIlr",
        "outputId": "5fea8f3e-0701-49a5-94bc-4d08810198dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        subreddit  label\n",
            "0  povertyfinance      2\n",
            "1  povertyfinance      2\n",
            "2  povertyfinance      2\n",
            "3  povertyfinance      2\n",
            "4  povertyfinance      2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GR8Odolc5cle",
        "outputId": "88ba4815-d4fa-4d51-d163-9b6cc1e43a7d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              post_text       subreddit  \\\n",
              "0     Two years ago I posted the following message o...  povertyfinance   \n",
              "1     Two years ago I posted the following message o...  povertyfinance   \n",
              "2     Two years ago I posted the following message o...  povertyfinance   \n",
              "3     Two years ago I posted the following message o...  povertyfinance   \n",
              "4     Two years ago I posted the following message o...  povertyfinance   \n",
              "...                                                 ...             ...   \n",
              "1251  Hello everyone! I will try to keep this short ...      Alzheimers   \n",
              "1252  Hello everyone! I will try to keep this short ...      Alzheimers   \n",
              "1253  Hello everyone! I will try to keep this short ...      Alzheimers   \n",
              "1254  Hello everyone! I will try to keep this short ...      Alzheimers   \n",
              "1255  Hello everyone! I will try to keep this short ...      Alzheimers   \n",
              "\n",
              "                                           clean_tokens  label  \n",
              "0     [two, years, ago, posted, following, message, ...      2  \n",
              "1     [two, years, ago, posted, following, message, ...      2  \n",
              "2     [two, years, ago, posted, following, message, ...      2  \n",
              "3     [two, years, ago, posted, following, message, ...      2  \n",
              "4     [two, years, ago, posted, following, message, ...      2  \n",
              "...                                                 ...    ...  \n",
              "1251  [hello, everyone, try, keep, short, sweet, wel...      0  \n",
              "1252  [hello, everyone, try, keep, short, sweet, wel...      0  \n",
              "1253  [hello, everyone, try, keep, short, sweet, wel...      0  \n",
              "1254  [hello, everyone, try, keep, short, sweet, wel...      0  \n",
              "1255  [hello, everyone, try, keep, short, sweet, wel...      0  \n",
              "\n",
              "[1256 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ec3d143-ac30-4887-afd3-aeee51507ab6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_text</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>clean_tokens</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two years ago I posted the following message o...</td>\n",
              "      <td>povertyfinance</td>\n",
              "      <td>[two, years, ago, posted, following, message, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Two years ago I posted the following message o...</td>\n",
              "      <td>povertyfinance</td>\n",
              "      <td>[two, years, ago, posted, following, message, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Two years ago I posted the following message o...</td>\n",
              "      <td>povertyfinance</td>\n",
              "      <td>[two, years, ago, posted, following, message, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Two years ago I posted the following message o...</td>\n",
              "      <td>povertyfinance</td>\n",
              "      <td>[two, years, ago, posted, following, message, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Two years ago I posted the following message o...</td>\n",
              "      <td>povertyfinance</td>\n",
              "      <td>[two, years, ago, posted, following, message, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>Hello everyone! I will try to keep this short ...</td>\n",
              "      <td>Alzheimers</td>\n",
              "      <td>[hello, everyone, try, keep, short, sweet, wel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>Hello everyone! I will try to keep this short ...</td>\n",
              "      <td>Alzheimers</td>\n",
              "      <td>[hello, everyone, try, keep, short, sweet, wel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>Hello everyone! I will try to keep this short ...</td>\n",
              "      <td>Alzheimers</td>\n",
              "      <td>[hello, everyone, try, keep, short, sweet, wel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>Hello everyone! I will try to keep this short ...</td>\n",
              "      <td>Alzheimers</td>\n",
              "      <td>[hello, everyone, try, keep, short, sweet, wel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>Hello everyone! I will try to keep this short ...</td>\n",
              "      <td>Alzheimers</td>\n",
              "      <td>[hello, everyone, try, keep, short, sweet, wel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1256 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ec3d143-ac30-4887-afd3-aeee51507ab6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ec3d143-ac30-4887-afd3-aeee51507ab6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ec3d143-ac30-4887-afd3-aeee51507ab6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-11198165-f48f-4a22-ae78-57d929379981\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11198165-f48f-4a22-ae78-57d929379981')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-11198165-f48f-4a22-ae78-57d929379981 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3f68c83d-dd53-465e-8a6b-24909c2cb568\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3f68c83d-dd53-465e-8a6b-24909c2cb568 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1256,\n  \"fields\": [\n    {\n      \"column\": \"post_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 239,\n        \"samples\": [\n          \"So I was rear ended in Feb of 2024, my lawyer called today and said he was able to settle and I will be receiving about 20k in pain and suffering damages. Because of the accident we had to take out a loan for a car and bought a 2024 Toyota Corolla. At the time the loan was 27k 640/month. We aggressively paid down the loan over the last year and half so now it's 13k. We refinanced and got a lower interest rate and payment is now 315/month. We are currently sharing the vehicle to get ourselves to work, myself to college and our daughter to preschool. My question is, would it be better to use the money to pay off the loan and use the rest as down payment for another car or use it all to buy a 2nd car cash?\\n\\nI would like to get a used RAV4 or Nissan Rogue but any that I look at are 25k with 30000 miles. \",\n          \"How would you make the most of it?\",\n          \"I\\u2019ve realized that small changes in thinking, like focusing on progress instead of perfection, can make a huge difference in daily life. Have you had a mental shift or positive thought that helped you handle challenges better or feel more motivated?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subreddit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"povertyfinance\",\n          \"GetMotivated\",\n          \"Alzheimers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vectorization"
      ],
      "metadata": {
        "id": "a5D_sICB5W8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TF-IDF"
      ],
      "metadata": {
        "id": "TB18r4SO5vWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "df['clean_text'] = df['clean_tokens'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "\n",
        "X_tfidf = tfidf.fit_transform(df['clean_text'])\n",
        "\n",
        "print(\"TF-IDF Matrix Shape:\", X_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OgAZlXTzIoQ",
        "outputId": "fa2ab8fb-236f-4d86-a225-fc9506667d69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix Shape: (1256, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word2Vec"
      ],
      "metadata": {
        "id": "533gohom6ZgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2nraU8_zIq3",
        "outputId": "5ab818b9-beeb-4012-a166-5c2cf0f95174"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6MQn_q_IzItk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Word2Vec\n",
        "\n",
        "w2v_model = Word2Vec(sentences=df['clean_tokens'], vector_size=77, window=7, min_count=1, workers=5)\n",
        "\n",
        "embedding_dim = w2v_model.vector_size"
      ],
      "metadata": {
        "id": "iCldSZ_ezIwM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Word Index using Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['clean_tokens'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df['clean_tokens'])\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HMxiPZjzI1s",
        "outputId": "9aff8d3d-b274-46d8-9b9d-0a99802ddfb0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 5979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pad the sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "maxlen = 75\n",
        "X_seq = pad_sequences(sequences, maxlen=maxlen, padding='post')"
      ],
      "metadata": {
        "id": "LY5hu6ADzI4c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original:\", sequences[1])\n",
        "print(\"Padded:\", X_seq[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4-aGy9DKkjY",
        "outputId": "72ab3e75-e7e1-408c-8528-b20570a15635"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: [90, 20, 111, 532, 1051, 1326, 1052, 160, 1053, 750, 27, 807, 1327, 712, 1775, 250, 58, 1328, 1054, 1776, 334, 237, 260, 1777, 29, 1055, 2725, 1778, 1056, 243, 19, 93, 543, 104, 2726, 2727, 1779, 2728, 1055, 2729, 137, 362, 47, 436, 2730, 2731, 57, 2732, 1329, 544, 174, 1327, 2733, 285, 1778, 2734, 41, 1055, 1711, 2735, 1329, 2736, 2737, 504, 2738, 2739, 4, 256, 1056, 1780, 750, 27, 4, 1781, 13, 1056, 2740, 265, 27, 220, 29, 164, 1782, 5, 2741, 1646, 27, 2742, 737, 69, 1783, 27, 639, 2743, 135, 1190, 1330, 55, 593, 2744, 265, 1784, 372, 681, 1331, 45, 91, 1331, 1327, 67, 42, 2745, 34, 37, 244, 865, 216, 206, 1332, 2746, 1331, 28, 2747, 1332, 216, 1056, 1333, 120, 2748, 261, 639, 1057, 1055, 4, 2402, 206, 751, 350, 170, 16, 2749, 1332, 42, 27, 24, 516, 505, 1334, 640, 67, 1335, 593, 2750, 2751, 70, 387, 3, 693, 2752, 59, 516, 1785, 2753, 1786, 517, 1336, 59, 1058, 593, 192, 2754, 2755, 132, 461, 25, 86, 71, 532, 97, 422, 86, 2610, 2756, 573, 320, 68, 14, 1059, 1589, 2757, 752, 320, 1337, 2758, 7, 1787, 2759, 751, 2760, 195, 21, 713, 2761, 1326, 1788, 1647, 462, 1060, 132, 27, 172, 102, 2762, 750, 27, 1338, 86, 594, 714, 2763, 715, 1262, 2764, 750, 2765, 161, 641, 1335, 461, 143, 1263, 1339, 2766, 1052, 2767, 712, 2768, 1329, 61, 59, 516, 86, 34, 69, 1334, 210, 172, 86, 878, 30, 86, 34, 750, 1334, 129, 3, 642, 2769, 866, 298, 2770, 397, 4, 639, 211]\n",
            "Padded: [ 752  320 1337 2758    7 1787 2759  751 2760  195   21  713 2761 1326\n",
            " 1788 1647  462 1060  132   27  172  102 2762  750   27 1338   86  594\n",
            "  714 2763  715 1262 2764  750 2765  161  641 1335  461  143 1263 1339\n",
            " 2766 1052 2767  712 2768 1329   61   59  516   86   34   69 1334  210\n",
            "  172   86  878   30   86   34  750 1334  129    3  642 2769  866  298\n",
            " 2770  397    4  639  211]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Embedding Matrix\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, idx in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[idx] = w2v_model.wv[word]"
      ],
      "metadata": {
        "id": "d1MBM4aZzI7E"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embedding Vector for word finance\n",
        "word = 'finance'\n",
        "if word in w2v_model.wv:\n",
        "    print(f\"Embedding vector for '{word}':\\n\", w2v_model.wv[word])\n",
        "else:\n",
        "    print(f\"'{word}' not found in vocab.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2IKoHBIzJDW",
        "outputId": "206a0965-51a6-4d6a-a8e4-cab2b05ce02d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding vector for 'finance':\n",
            " [ 0.01640831  0.00219703 -0.00924684 -0.00051995  0.00524127 -0.01251659\n",
            " -0.00146536 -0.01118017  0.01560557 -0.00699945  0.01212521  0.01163151\n",
            " -0.00554122  0.01370015 -0.00456735 -0.01507047 -0.00364862 -0.00620186\n",
            " -0.00547724 -0.007319   -0.01653562  0.0062901  -0.00769353 -0.00611156\n",
            " -0.0098087   0.01011994  0.00752469 -0.00193887 -0.00109277 -0.00132659\n",
            " -0.00507468  0.00716763 -0.00249068  0.00026615 -0.00685409 -0.00683156\n",
            " -0.00724503  0.0052756  -0.0062282   0.01742051 -0.00078006 -0.009508\n",
            " -0.00051547 -0.00528923  0.00961807  0.00701195  0.00389526 -0.00260215\n",
            "  0.0151155  -0.0112946   0.00847435 -0.00184977 -0.01087169  0.00535313\n",
            "  0.01125289  0.0146576  -0.01017706  0.01078991  0.00135853 -0.01986548\n",
            " -0.00306702 -0.00583805  0.00858769 -0.0109171   0.01492798 -0.00204221\n",
            " -0.0021817   0.00172787  0.00405961  0.00808792  0.00031403  0.00682291\n",
            " -0.00528838 -0.00887902  0.01070243  0.00231718 -0.00077206]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Embedding Matrix for an index (1st word)\n",
        "index = 1\n",
        "print(f\"Embedding vector from embedding_matrix for index {index}:\\n\", embedding_matrix[index])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrKLFEADzJF0",
        "outputId": "d748eab7-f5b4-45cf-e83e-2137c4d831de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding vector from embedding_matrix for index 1:\n",
            " [-0.64122856  0.22891977  0.61218911 -1.11599398  0.79354805  0.03387818\n",
            "  1.10653138  0.71104717 -0.525796   -0.21786588  0.43475494 -0.85807127\n",
            " -0.05970793  0.10820962  1.13620901  0.92792445 -0.55006081  0.08729704\n",
            "  0.98360831  0.37689778  0.80093122 -0.50923604 -0.24017115  0.96107298\n",
            "  0.34756243 -0.54202867 -0.25209525 -0.34591046 -0.52726209 -0.22488232\n",
            " -0.98359489 -0.40564656  0.36134368  0.76691699  0.03082436 -0.32625246\n",
            "  1.22848153 -0.19601375 -0.31726065 -1.21924484 -0.83678746 -0.75675786\n",
            " -1.04725659 -0.99410439 -0.58476925  0.5180608   0.12724784  1.06259596\n",
            " -0.14489195  0.18845807 -0.20068409 -0.69126296 -0.18936768 -0.18888956\n",
            " -0.44081569 -0.69935727 -0.05674208  0.11353314  0.50528151  1.38719451\n",
            " -0.21127383  0.07296522 -0.152622    0.84946483 -0.624358   -0.4061524\n",
            " -0.98098129  0.16213295 -0.52818251  0.87266707 -0.37747243 -0.32672948\n",
            " -0.06385903  0.57112187 -0.19251622  1.0788703  -1.40410304]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Building"
      ],
      "metadata": {
        "id": "lYMwfPc-9FnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split the Dataset"
      ],
      "metadata": {
        "id": "34E-jQ7T9Nip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = X_seq\n",
        "y = df['label'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#Shapes\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPz6ifgqzJIr",
        "outputId": "52828de4-015e-4e15-8771-0b4cf09705c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1004, 75)\n",
            "Test shape: (252, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build and Train the Models"
      ],
      "metadata": {
        "id": "IQDxTick9pjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression using TF-IDF"
      ],
      "metadata": {
        "id": "ws7exqZ5-Eqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "#TF-IDF input and labels\n",
        "X = X_tfidf\n",
        "y = df['label']\n",
        "\n",
        "#Spliting\n",
        "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#Train model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "#Evaluation\n",
        "y_pred_tfidf = log_reg.predict(X_test_tfidf)\n",
        "\n",
        "#Metrics\n",
        "print(\"Logistic Regression via TF-IDF:\\n\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_tfidf, y_pred_tfidf))\n",
        "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa3mrURdzJLN",
        "outputId": "110ebfba-7c94-4e84-ed6d-62c8949d5388"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression via TF-IDF:\n",
            "\n",
            "Accuracy: 0.9325396825396826\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "    Alzheimers       1.00      0.95      0.98        84\n",
            "  GetMotivated       0.83      1.00      0.91        84\n",
            "povertyfinance       1.00      0.85      0.92        84\n",
            "\n",
            "      accuracy                           0.93       252\n",
            "     macro avg       0.94      0.93      0.93       252\n",
            "  weighted avg       0.94      0.93      0.93       252\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN"
      ],
      "metadata": {
        "id": "VU2754aS-bbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "#One Hot Encoder\n",
        "y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "y_test_cat = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "#EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "#RNN Model\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=X_train.shape[1],\n",
        "                        trainable=True))\n",
        "rnn_model.add(SimpleRNN(64, return_sequences=False))\n",
        "rnn_model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "#Compiling\n",
        "rnn_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=0.001),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "#Training\n",
        "rnn = rnn_model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_data=(X_test, y_test_cat),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Evaluating\n",
        "loss, accuracy = rnn_model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"\\nRNN Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "#Prediction\n",
        "y_pred_probs = rnn_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"\\nRNN Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD7KUckMzJN1",
        "outputId": "8dbc3404-b7a5-4136-c181-7280a16ce49b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.4153 - loss: 1.0992 - val_accuracy: 0.6151 - val_loss: 0.9317\n",
            "Epoch 2/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7080 - loss: 0.8394 - val_accuracy: 0.7897 - val_loss: 0.5544\n",
            "Epoch 3/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9012 - loss: 0.3580 - val_accuracy: 0.9127 - val_loss: 0.2551\n",
            "Epoch 4/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.9514 - loss: 0.1928 - val_accuracy: 0.9127 - val_loss: 0.2382\n",
            "Epoch 5/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9435 - loss: 0.1501 - val_accuracy: 0.9127 - val_loss: 0.2046\n",
            "Epoch 6/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9651 - loss: 0.1147 - val_accuracy: 0.9127 - val_loss: 0.2343\n",
            "Epoch 7/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9562 - loss: 0.1470 - val_accuracy: 0.9127 - val_loss: 0.2178\n",
            "Epoch 8/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9674 - loss: 0.1116 - val_accuracy: 0.9127 - val_loss: 0.2299\n",
            "\n",
            "RNN Accuracy: 0.9127\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "\n",
            "RNN Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "    Alzheimers       1.00      0.89      0.94        84\n",
            "  GetMotivated       0.79      1.00      0.88        84\n",
            "povertyfinance       1.00      0.85      0.92        84\n",
            "\n",
            "      accuracy                           0.91       252\n",
            "     macro avg       0.93      0.91      0.91       252\n",
            "  weighted avg       0.93      0.91      0.91       252\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM"
      ],
      "metadata": {
        "id": "hlnz7nBoAk4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "#One Hot Encoder\n",
        "y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "y_test_cat = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "#EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "#LSTM Model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(input_dim=vocab_size,\n",
        "                    output_dim=embedding_dim,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=X_train.shape[1],\n",
        "                    trainable=True))\n",
        "lstm_model.add(LSTM(150, return_sequences=True))\n",
        "lstm_model.add(LSTM(150))\n",
        "lstm_model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "#Compiling\n",
        "lstm_model.compile(loss='categorical_crossentropy',\n",
        "                   optimizer=Adam(learning_rate=0.001),\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "#Training\n",
        "lstm = lstm_model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_data=(X_test, y_test_cat),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Evaluating\n",
        "loss, accuracy = lstm_model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"\\nLSTM Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "#Prediction\n",
        "y_pred_probs = lstm_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "#Report\n",
        "print(\"\\nLSTM Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG3iOh-7zJQZ",
        "outputId": "ebab670e-a8e7-4ef0-f9e1-b87f550a48c8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 284ms/step - accuracy: 0.3520 - loss: 1.1108 - val_accuracy: 0.4127 - val_loss: 1.0749\n",
            "Epoch 2/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.4204 - loss: 1.0667 - val_accuracy: 0.4048 - val_loss: 1.0495\n",
            "Epoch 3/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.4768 - loss: 1.0323 - val_accuracy: 0.4405 - val_loss: 0.9694\n",
            "Epoch 4/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 329ms/step - accuracy: 0.6283 - loss: 0.7399 - val_accuracy: 0.7579 - val_loss: 0.5435\n",
            "Epoch 5/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 268ms/step - accuracy: 0.7533 - loss: 0.4757 - val_accuracy: 0.6944 - val_loss: 0.6648\n",
            "Epoch 6/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 291ms/step - accuracy: 0.7525 - loss: 0.5325 - val_accuracy: 0.7500 - val_loss: 0.4886\n",
            "Epoch 7/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 331ms/step - accuracy: 0.8790 - loss: 0.3116 - val_accuracy: 0.8929 - val_loss: 0.3547\n",
            "Epoch 8/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 326ms/step - accuracy: 0.9513 - loss: 0.1393 - val_accuracy: 0.9008 - val_loss: 0.2319\n",
            "Epoch 9/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 273ms/step - accuracy: 0.9646 - loss: 0.1037 - val_accuracy: 0.9048 - val_loss: 0.2548\n",
            "Epoch 10/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 328ms/step - accuracy: 0.9555 - loss: 0.1104 - val_accuracy: 0.9048 - val_loss: 0.2602\n",
            "Epoch 11/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 323ms/step - accuracy: 0.9673 - loss: 0.0828 - val_accuracy: 0.9206 - val_loss: 0.2571\n",
            "\n",
            "LSTM Accuracy: 0.9008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7aef1aad4fe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step\n",
            "\n",
            "LSTM Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "    Alzheimers       0.96      0.95      0.96        84\n",
            "  GetMotivated       0.79      1.00      0.88        84\n",
            "povertyfinance       1.00      0.75      0.86        84\n",
            "\n",
            "      accuracy                           0.90       252\n",
            "     macro avg       0.92      0.90      0.90       252\n",
            "  weighted avg       0.92      0.90      0.90       252\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final Prediction"
      ],
      "metadata": {
        "id": "MUne0bMTGnTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from cleantext import clean\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "#Load tokenizer, label encoder, and model\n",
        "with open('tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "model = load_model('/content/lstm_model.h5')\n",
        "\n",
        "#Constants\n",
        "MAXLEN = 75\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#Text preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = clean(\n",
        "        text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=True,\n",
        "        lower=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=True\n",
        "    )\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "    return filtered_tokens\n",
        "\n",
        "#Final Prediction\n",
        "def predict_subreddit(text):\n",
        "    tokens = preprocess_text(text)\n",
        "    sequence = tokenizer.texts_to_sequences([tokens])\n",
        "    padded = pad_sequences(sequence, maxlen=MAXLEN, padding='post')\n",
        "    pred = model.predict(padded)\n",
        "    pred_class = np.argmax(pred, axis=1)\n",
        "    label = label_encoder.inverse_transform(pred_class)[0]\n",
        "    return label\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0kAfifiExTX",
        "outputId": "17b95fc5-75d8-4bfc-f02b-e8dbe81f7116"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I feel really discouraged lately, looking for some motivation.\"\n",
        "predicted_label = predict_subreddit(text)\n",
        "print(\"Predicted Subreddit:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3y88YmDE-qe",
        "outputId": "e3a11b0f-8c5e-42bd-9bbf-8a93922df1b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Predicted Subreddit: GetMotivated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pickel"
      ],
      "metadata": {
        "id": "EviejHdeGrLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#Savetokenizer\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "#Save label encoder\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "#Save LSTM model in HDF5\n",
        "lstm_model.save(\"lstm_model.h5\")\n",
        "\n",
        "print(\"Tokenizer, LabelEncoder, and LSTM model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrE3bsMHzJTG",
        "outputId": "66924f3f-b816-4b1e-d50f-769a8bb9fc6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer, LabelEncoder, and LSTM model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradio"
      ],
      "metadata": {
        "id": "ho0zF3_O8upm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "#Load model and tools\n",
        "model = load_model(\"lstm_model.h5\")\n",
        "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "#Preprocessing\n",
        "def preprocess(text):\n",
        "    text = clean(text,\n",
        "                 fix_unicode=True, to_ascii=True, lower=True,\n",
        "                 no_urls=True, no_emails=True, no_phone_numbers=True,\n",
        "                 no_currency_symbols=True, no_punct=True)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "#Predict\n",
        "def predict_subreddit(post_text):\n",
        "    clean_text = preprocess(post_text)\n",
        "    seq = tokenizer.texts_to_sequences([clean_text])\n",
        "    padded = pad_sequences(seq, maxlen=100, padding='post')\n",
        "    pred = model.predict(padded)\n",
        "    class_idx = np.argmax(pred, axis=1)[0]\n",
        "    return label_encoder.inverse_transform([class_idx])[0]\n",
        "\n",
        "#Gradio Interface\n",
        "demo = gr.Interface(fn=predict_subreddit,\n",
        "                    inputs=gr.Textbox(lines=5, placeholder=\"Enter a Reddit post...\"),\n",
        "                    outputs=\"text\",\n",
        "                    title=\"Subreddit Post Classifier (LSTM)\",\n",
        "                    description=\"Paste a Reddit post and get predicted subreddit.\")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "0yTqZpnf7nCO",
        "outputId": "92e0aa0c-ee70-4746-88c0-f9dd2ef16ba0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://168e62980317cd14b5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://168e62980317cd14b5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}